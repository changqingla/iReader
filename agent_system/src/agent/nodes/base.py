"""Agent èŠ‚ç‚¹åŸºç±»å’Œå·¥å…·æ–¹æ³•"""
from typing import Dict, Any, List, Optional, Tuple, TypedDict

from langchain_openai import ChatOpenAI

from ..state import AgentState
from ..thinking import ThoughtGeneratorManager
from ...utils.logger import get_logger
from ...utils.recall_cache import RecallToolCache
from ...tools import RecallTool, WebSearchTool
from ..constants import RECALL_TOOL_CACHE_SIZE

from context.session_manager import SessionManager
from context.context_injector import ContextInjector

logger = get_logger(__name__)


# ============================================================================
# ç±»å‹å®šä¹‰
# ============================================================================

class RecallStepInfo(TypedDict):
    """å¬å›æ­¥éª¤ä¿¡æ¯"""
    index: int
    step: Dict[str, Any]


class StepWithQuery(TypedDict):
    """å¸¦æŸ¥è¯¢çš„æ­¥éª¤ä¿¡æ¯"""
    index: int
    step: Dict[str, Any]
    query: str
    decision: Optional[Dict[str, Any]]


class BaseAgentNode:
    """èŠ‚ç‚¹åŸºç±»ï¼Œæä¾›å…¬å…±åŠŸèƒ½"""
    
    def __init__(
        self,
        llm: ChatOpenAI,
        recall_tool: RecallTool,
        session_manager: SessionManager,
        web_search_tool: Optional[WebSearchTool] = None
    ):
        """
        åˆå§‹åŒ–åŸºç¡€èŠ‚ç‚¹
        
        Args:
            llm: è¯­è¨€æ¨¡å‹
            recall_tool: æ–‡æ¡£å¬å›å·¥å…·
            session_manager: ä¼šè¯ç®¡ç†å™¨
            web_search_tool: ç½‘é¡µæœç´¢å·¥å…·ï¼ˆå¯é€‰ï¼‰
        """
        self.llm = llm
        self.recall_tool = recall_tool
        self.session_manager = session_manager
        self.web_search_tool = web_search_tool
        self.context_injector = ContextInjector()
        self.thought_manager = ThoughtGeneratorManager()
        self._recall_cache = RecallToolCache(max_size=RECALL_TOOL_CACHE_SIZE)
    
    async def _get_conversation_context_async(
        self,
        state: AgentState,
        stage: str = "intent_recognition"
    ) -> str:
        """
        å¼‚æ­¥è·å–å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆä½¿ç”¨çº¿ç¨‹æ± é¿å…é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰
        
        Args:
            state: Agent çŠ¶æ€
            stage: å¤„ç†é˜¶æ®µï¼ˆintent_recognition/planning/answer_generation/simple_interactionï¼‰
            
        Returns:
            æ ¼å¼åŒ–çš„å¯¹è¯å†å²å­—ç¬¦ä¸²
        """
        import asyncio
        return await asyncio.to_thread(self._get_conversation_context_sync, state, stage)
    
    def _get_conversation_context_sync(
        self,
        state: AgentState,
        stage: str = "intent_recognition"
    ) -> str:
        """
        åŒæ­¥è·å–å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰
        
        Args:
            state: Agent çŠ¶æ€
            stage: å¤„ç†é˜¶æ®µ
            
        Returns:
            æ ¼å¼åŒ–çš„å¯¹è¯å†å²å­—ç¬¦ä¸²
        """
        session_id = state.get('session_id')
        if not session_id:
            return ""
        
        inject_methods = {
            "intent_recognition": self.context_injector.inject_for_intent_recognition,
            "planning": self.context_injector.inject_for_planning,
            "answer_generation": self.context_injector.inject_for_answer_generation,
            "simple_interaction": self.context_injector.inject_for_simple_interaction,
        }
        
        inject_method = inject_methods.get(stage)
        if not inject_method:
            logger.warning(f"Unknown stage: {stage}")
            return ""
        
        messages = inject_method(session_id)
        if not messages:
            return ""
        
        return self.context_injector.format_messages_for_prompt(messages)
    
    def _get_conversation_context(
        self,
        state: AgentState,
        stage: str = "intent_recognition"
    ) -> str:
        """
        åŒæ­¥è·å–å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆå…¼å®¹æ—§ä»£ç ï¼‰
        
        æ³¨æ„ï¼šåœ¨å¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­åº”ä½¿ç”¨ _get_conversation_context_async
        """
        return self._get_conversation_context_sync(state, stage)
    
    def _smart_split_document_summaries(
        self,
        document_summaries: Dict[str, str],
        max_tokens: int
    ) -> List[List[Tuple[str, str]]]:
        """
        æ™ºèƒ½åˆ‡åˆ†æ–‡æ¡£æ€»ç»“ï¼Œç¡®ä¿æ¯ç»„åœ¨ token é˜ˆå€¼å†…
        
        Args:
            document_summaries: æ–‡æ¡£æ€»ç»“å­—å…¸ {doc_id: summary}
            max_tokens: Token é˜ˆå€¼
            
        Returns:
            åˆ‡åˆ†åçš„æ–‡æ¡£ç»„åˆ—è¡¨ï¼Œæ¯ç»„ä¸º [(doc_id, summary), ...]
        """
        from context.token_counter import calculate_tokens
        
        items = list(document_summaries.items())
        total_count = len(items)
        
        logger.info(f"ğŸ“Š æ™ºèƒ½åˆ‡åˆ†ï¼š{total_count} ä¸ªæ–‡æ¡£æ€»ç»“ï¼Œé˜ˆå€¼ {max_tokens:,} tokens")
        
        all_text = "\n\n".join([summary for _, summary in items])
        total_tokens = calculate_tokens(all_text)
        
        logger.info(f"   æ€»token: {total_tokens:,}")
        
        if total_tokens < max_tokens:
            logger.info(f"   âœ… æ— éœ€åˆ‡åˆ†")
            return [items]
        
        logger.info(f"   âš ï¸ è¶…è¿‡é˜ˆå€¼ï¼Œå¼€å§‹åˆ‡åˆ†")
        
        def _recursive_split(items_to_split):
            if len(items_to_split) == 1:
                return [items_to_split]
            
            mid = len(items_to_split) // 2
            group1 = items_to_split[:mid]
            group2 = items_to_split[mid:]
            
            group1_text = "\n\n".join([summary for _, summary in group1])
            group2_text = "\n\n".join([summary for _, summary in group2])
            
            group1_tokens = calculate_tokens(group1_text)
            group2_tokens = calculate_tokens(group2_text)
            
            result = []
            
            if group1_tokens < max_tokens:
                result.append(group1)
            else:
                result.extend(_recursive_split(group1))
            
            if group2_tokens < max_tokens:
                result.append(group2)
            else:
                result.extend(_recursive_split(group2))
            
            return result
        
        groups = _recursive_split(items)
        logger.info(f"   âœ… åˆ‡åˆ†å®Œæˆï¼š{len(groups)} ç»„")
        
        return groups
    
    def _build_collected_info_for_answer(self, state: AgentState) -> str:
        """
        æ„å»ºç”¨äºç­”æ¡ˆç”Ÿæˆçš„ä¿¡æ¯ä¸Šä¸‹æ–‡
        
        æ”¯æŒä¸‰ç§æ¨¡å¼ï¼š
        1. æ–‡æ¡£æ€»ç»“æ¨¡å¼ï¼šä½¿ç”¨ document_summaries
        2. ç›´æ¥å†…å®¹æ¨¡å¼ï¼šä½¿ç”¨ direct_content
        3. å¬å›æ¨¡å¼ï¼šä½¿ç”¨ execution_results
        
        Args:
            state: Agent çŠ¶æ€
            
        Returns:
            æ”¶é›†çš„ä¿¡æ¯æ–‡æœ¬
            
        Raises:
            RuntimeError: æ— å¯ç”¨å†…å®¹æ—¶æŠ›å‡º
        """
        use_direct_content = state.get("use_direct_content", False)
        document_summaries = state.get("document_summaries", {})
        
        if document_summaries:
            logger.info(f"ğŸ“š ä½¿ç”¨æ–‡æ¡£æ€»ç»“ç”Ÿæˆç­”æ¡ˆï¼š{len(document_summaries)} ä¸ªæ–‡æ¡£")
            document_names = state.get("document_names", {}) or {}
            
            summary_lines = []
            for i, (doc_id, summary) in enumerate(document_summaries.items(), 1):
                doc_display_name = document_names.get(doc_id, doc_id)
                summary_lines.append(f"## æ–‡æ¡£ {i}: {doc_display_name}")
                summary_lines.append(summary)
                summary_lines.append("")
            
            return "\n".join(summary_lines)
        
        elif use_direct_content:
            content = state.get("direct_content", "")
            if not content:
                raise RuntimeError("Direct content mode enabled but no direct_content provided")
            
            logger.info(f"ğŸ“„ ä½¿ç”¨ç›´æ¥å†…å®¹æ¨¡å¼ï¼Œé•¿åº¦: {len(content)} å­—ç¬¦")
            return content
        
        else:
            execution_results = state.get("execution_results", [])
            if not execution_results:
                raise RuntimeError("No execution results found for answer generation")
            
            logger.info(f"ğŸ“Š ä½¿ç”¨å¬å›ç»“æœç”Ÿæˆç­”æ¡ˆï¼š{len(execution_results)} ä¸ª")
            
            recall_lines = []
            for i, result in enumerate(execution_results, 1):
                if result.get("result"):
                    step_title = result.get("step_title", f"æ­¥éª¤ {i}")
                    recall_lines.append(f"## {step_title}\n{result['result']}\n")
            
            return "\n".join(recall_lines)
