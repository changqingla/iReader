# 智能体工作流详细介绍

## 一、系统概述

本智能体系统是一个面向学术文献的智能问答助手，采用多阶段流水线架构处理用户查询。系统能够根据用户问题的类型和关联文档的数量，动态选择最优的处理策略，支持文献总结、综述生成、论文评审、文献问答等多种学术场景。

### 核心特性

- **多意图识别**：支持 5 种任务意图的自动识别
- **智能策略选择**：根据文档数量和内容大小自动选择最优处理策略
- **流式输出**：支持实时流式响应，提升用户体验
- **上下文管理**：完整的会话历史管理和上下文压缩机制
- **并行处理**：多文档场景下的并行处理优化
- **缓存机制**：文档总结缓存，避免重复计算

---

## 二、系统架构

### 2.1 整体架构图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                              用户请求                                        │
└─────────────────────────────────────────────────────────────────────────────┘
                                      │
                                      ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                           后端服务层 (RAG Service)                           │
│  • 获取用户 ES 索引  • 预加载文档内容  • 调用 Agent System                    │
└─────────────────────────────────────────────────────────────────────────────┘
                                      │
                                      ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                           智能体核心 (IntelligentAgent)                      │
│  • 会话管理  • 上下文计算  • 工具实例化  • 工作流编排                         │
└─────────────────────────────────────────────────────────────────────────────┘
                                      │
                    ┌─────────────────┼─────────────────┐
                    ▼                 ▼                 ▼
            ┌───────────┐     ┌───────────┐     ┌───────────┐
            │ 文档节点   │     │ 规划节点   │     │ 执行节点   │
            │ Document  │     │ Planning  │     │ Execution │
            │  Nodes    │     │  Nodes    │     │  Nodes    │
            └───────────┘     └───────────┘     └───────────┘
                    │                 │                 │
                    └─────────────────┼─────────────────┘
                                      ▼
                              ┌───────────┐
                              │ 答案节点   │
                              │  Answer   │
                              │  Nodes    │
                              └───────────┘
```

### 2.2 核心组件

| 组件 | 职责 |
|------|------|
| **IntelligentAgent** | 主控制器，负责初始化、参数验证、工作流编排 |
| **DocumentNodes** | 文档检查、多文档总结生成 |
| **PlanningNodes** | 意图识别、策略选择、子问题生成、计划生成 |
| **ExecutionNodes** | 执行召回操作，支持并行召回 |
| **AnswerNodes** | 答案生成、简单交互处理、多文档综合 |
| **SessionManager** | 会话生命周期管理、消息存储、上下文压缩 |
| **RecallTool** | 文档召回工具，通过 HTTP API 检索文档知识库 |
| **WebSearchTool** | 网页搜索工具，支持 Tavily 和 Bocha 搜索引擎 |

---

## 三、工作流详解

### 3.1 工作流主流程图

```
用户请求
    │
    ▼
┌─────────────────┐
│  请求初始化      │ ← 加载会话、计算可用 tokens、创建工具实例
└─────────────────┘
    │
    ▼
┌─────────────────┐
│ 文档处理模式判断  │ ← 根据文档数量和大小初步判断处理模式
└─────────────────┘
    │
    ▼
┌─────────────────┐     无文档且无内容     ┌─────────────────┐
│   文档检查       │ ─────────────────────→│  简单交互流程    │
│ document_check  │                        │ simple_interact │
└─────────────────┘                        └─────────────────┘
    │ 有文档或有内容                                │
    ▼                                              │
┌─────────────────┐     SIMPLE_INTERACTION         │
│   意图识别       │ ─────────────────────────────→│
│ intent_recogn.  │                                │
└─────────────────┘                                │
    │ 其他意图                                      │
    ▼                                              │
┌─────────────────┐                                │
│   策略选择       │                                │
│ strategy_select │                                │
└─────────────────┘                                │
    │                                              │
    ├─── full_content ───→ 跳过信息收集 ───────────┐│
    │                                              ││
    ├─── multi_doc_summary ───→ 文档总结节点 ─────┐││
    │                                             │││
    └─── chunk_recall ───→ 子问题 → 计划 → 执行 ─┐│││
                                                 ││││
                                                 ▼▼▼▼
                                          ┌─────────────────┐
                                          │    答案生成      │
                                          │ answer_generat. │
                                          └─────────────────┘
                                                  │
                                                  ▼
                                          ┌─────────────────┐
                                          │    会话保存      │
                                          └─────────────────┘
```


### 3.2 阶段详解

#### 第一阶段：请求初始化

当用户发起查询请求时，系统首先进行初始化准备工作：

**后端预处理**：
1. 获取用户的 ES 索引名称
2. 根据知识库 ID 和文档 ID 获取文档列表
3. 预加载文档内容：
   - 单文档场景：加载 `content`（单个文档的 markdown 内容）
   - 多文档场景：批量加载 `document_contents`（所有文档的完整内容字典）

**Agent 初始化**：
1. 加载或创建会话，获取历史对话上下文
2. 计算当前可用的上下文窗口大小：
   ```
   available_tokens = max_context_tokens - session_tokens - query_tokens - system_tokens - reserved_answer_tokens
   ```
3. 根据请求参数动态创建语言模型实例和工具实例

#### 第二阶段：文档处理模式判断

系统根据文档数量和内容大小，进行初步的模式判断：

| 场景 | 判断条件 | 处理方式 |
|------|---------|---------|
| 多文档场景 | 文档数量 ≥ 2 | 记录多文档场景，策略由后续节点决定 |
| 单文档（小） | 文档内容 < 可用上下文 × 阈值 | 设置 `use_direct_content = True` |
| 单文档（大） | 文档内容超过阈值 | 后续使用召回模式 |
| 无文档 | 无关联文档 | 在文档检查时判定为简单交互 |

#### 第三阶段：文档检查 (document_check_node)

检查用户是否关联了文档：

- **无文档场景**：如果没有关联任何文档且没有提供直接内容，系统判定为日常闲聊场景，设置 `detected_intent = SIMPLE_INTERACTION`，直接跳转到简单交互流程
- **有文档场景**：继续进入意图识别阶段

#### 第四阶段：意图识别 (intent_recognition_node)

分析用户问题的意图类型，支持以下五种意图：

| 意图类型 | 枚举值 | 说明 | 触发示例 |
|---------|--------|------|---------|
| 简单交互 | `SIMPLE_INTERACTION` | 日常对话、闲聊 | "你好"、"你能做什么" |
| 文献总结 | `LITERATURE_SUMMARY` | 对文献内容进行概括 | "总结一下"、"这篇论文讲了什么" |
| 综述生成 | `REVIEW_GENERATION` | 基于多篇文献生成综述 | "写一篇文献综述"、"综合分析这些论文" |
| 论文评审 | `PAPER_REVIEW` | 对论文进行学术评审 | "评审这篇论文"、"有什么缺陷" |
| 文献问答 | `LITERATURE_QA` | 针对文献的具体问题 | "使用了什么数据集"、"学习率是多少" |

**意图识别流程**：
1. 如果请求中指定了 `mode_type`，直接使用指定的意图类型
2. 否则调用 LLM 进行意图识别（最多重试 3 次）
3. 如果识别失败，默认使用 `SIMPLE_INTERACTION`

#### 第五阶段：策略选择 (strategy_selection_node)

根据意图类型和文档数量，选择信息收集策略：

```
策略选择逻辑：
if use_direct_content:
    strategy = "full_content"
elif doc_count > 1 and intent in [LITERATURE_SUMMARY, REVIEW_GENERATION]:
    strategy = "multi_doc_summary"
else:
    strategy = "chunk_recall"
```

**三种策略说明**：

| 策略 | 适用场景 | 处理方式 |
|------|---------|---------|
| `full_content` | 单文档且内容较小 | 直接使用完整文档内容，跳过信息收集 |
| `multi_doc_summary` | 多文档 + 文献总结/综述生成 | 并行为每篇文档生成压缩总结，再综合分析 |
| `chunk_recall` | 其他所有场景 | 分解子问题，从文档中检索相关片段 |

#### 第六阶段：信息收集

根据选择的策略执行不同的信息收集流程：

**直接内容模式 (full_content)**：
- 跳过信息收集阶段，直接进入答案生成
- 使用完整文档内容作为上下文

**多文档总结模式 (multi_doc_summary)**：
执行 `document_summary_node`：
1. 从 `document_contents` 获取各文档的完整内容
2. 对每篇文档进行大小检查：
   - 小文档（≤ 阈值）：直接使用完整内容生成总结
   - 大文档（> 阈值）：使用召回获取关键信息后生成总结
3. 使用 `asyncio.gather` 并行处理所有文档
4. 为每篇文档调用 LLM 生成压缩总结
5. 将所有总结存入 `document_summaries`

**分块召回模式 (chunk_recall)**：

分块召回模式包含三个子阶段：

1. **子问题生成** (sub_question_generation_node)
   - 将用户的复杂问题分解为多个独立的、面向检索的子问题
   - 每个子问题包含问题文本和目标文档 ID（可选）
   - 对于多文档场景，子问题会明确指定目标文档

2. **计划生成** (plan_generation_node)
   - 将每个子问题转换为一个召回步骤
   - 如果子问题生成失败，使用用户原始问题作为单个召回步骤

3. **执行阶段** (execution_node)
   - 检测连续的召回步骤，使用 `asyncio.gather` 并行执行
   - 对于指定了目标文档的步骤，只在该文档范围内检索
   - 收集所有步骤的召回结果

#### 第七阶段：答案生成 (answer_generation_node)

基于收集到的信息生成最终答案：

**多文档总结模式的答案生成**：
1. 获取各文档的压缩总结
2. 使用智能切分算法将文档总结分组，确保每组不超过上下文限制
3. 单组场景：直接生成最终答案
4. 多组场景：先为每组生成中间报告，再合并成最终答案

**其他模式的答案生成**：
1. 构建上下文信息（直接内容或召回结果）
2. 根据意图类型选择提示词模板
3. 调用 LLM 流式生成答案

**简单交互模式** (simple_interaction_node)：
1. 获取完整的对话历史
2. 如果启用了联网搜索，调用 WebSearchTool 获取搜索结果
3. 使用简单交互提示词生成回复

#### 第八阶段：会话保存

将用户问题和助手回答保存到会话历史中：
1. 异步保存用户消息
2. 异步保存助手消息
3. 自动更新会话统计信息


---

## 四、任务类型与处理策略矩阵

下表详细说明了不同任务类型在各种文档场景下的处理策略：

| 任务类型 | 无文档 | 单文档（小） | 单文档（大） | 多文档 |
|---------|--------|-------------|-------------|--------|
| **简单交互** | 直接回复 + 可选联网搜索 | - | - | - |
| **文献总结** | N/A | full_content → 直接总结 | chunk_recall → 召回后总结 | multi_doc_summary → 并行总结 → 综合分析 |
| **综述生成** | N/A | full_content → 直接生成 | chunk_recall → 召回后生成 | multi_doc_summary → 并行总结 → 综合综述 |
| **论文评审** | N/A | full_content → 直接评审 | chunk_recall → 召回后评审 | chunk_recall → 分文档召回 → 综合评审 |
| **文献问答** | N/A | full_content → 直接回答 | chunk_recall → 召回后回答 | chunk_recall → 分文档召回 → 综合回答 |

**说明**：
- "单文档（小）"：文档内容 token 数 < 可用上下文 × `direct_content_threshold`（默认 70%）
- "单文档（大）"：文档内容超过阈值，需要分块召回
- 多文档场景下，`LITERATURE_SUMMARY` 和 `REVIEW_GENERATION` 使用 `multi_doc_summary` 策略
- 多文档场景下，`PAPER_REVIEW` 和 `LITERATURE_QA` 使用 `chunk_recall` 策略

---

## 五、上下文注入策略

系统根据不同的处理阶段，注入不同数量的历史对话：

| 处理阶段 | 注入策略 | 说明 |
|---------|---------|------|
| 意图识别 | 最近 2 轮对话（4 条消息） | 足够理解上下文，避免过多干扰 |
| 执行规划 | 最近 2 轮对话（4 条消息） | 保持一致性 |
| 答案生成 | 最近 3 轮对话（6 条消息） | 需要更多上下文生成连贯答案 |
| 执行阶段 | 不注入历史对话 | 召回操作不需要对话历史 |
| 简单交互 | 所有活跃消息（包括压缩摘要） | 可能涉及"你刚才说了什么"等问题 |

**注入内容**：
- 如果存在压缩摘要，始终包含在注入内容的开头
- 然后是最近 N 轮的普通消息（user + assistant）

---

## 六、特殊处理机制

### 6.1 上下文压缩

当会话历史的 Token 数量超过压缩阈值（`max_context_tokens × 0.8`）时，系统会触发压缩机制：

1. 保留最近 30% 的消息不压缩
2. 将较早的 70% 消息压缩为摘要
3. 压缩摘要作为特殊消息类型存储
4. 原始消息标记为已压缩，不再参与后续注入

### 6.2 并行执行优化

系统在多个环节采用并行处理以提升性能：

| 场景 | 并行方式 |
|------|---------|
| 多文档总结 | `asyncio.gather` 并行处理各文档的总结生成 |
| 多步骤召回 | 检测连续的召回步骤，并行执行所有召回任务 |
| 异步 API 调用 | RecallTool 和 WebSearchTool 都支持异步执行 |
| 会话保存 | 使用 `asyncio.to_thread` 避免阻塞事件循环 |

### 6.3 并发控制

为避免大量文档场景下 API 限流和资源耗尽，系统使用 `asyncio.Semaphore` 限制并发：

- **最大并发数**：由 `MAX_CONCURRENT_LLM_CALLS` 常量控制（默认 10）
- **应用场景**：
  - 多文档总结阶段：限制同时进行的文档总结 LLM 调用
  - 多组报告生成阶段：限制同时进行的分组报告 LLM 调用
- **效果**：200 篇文档场景下，最多同时进行 10 个 LLM 调用

### 6.4 文档总结缓存

系统使用 Redis 缓存文档的压缩总结，避免重复生成：

**缓存设计**：
- **缓存键**：`doc_summary:{doc_id}:{content_hash}`
- **全局共享**：同一文档的总结可被所有用户复用
- **内容感知**：基于内容哈希，文档内容变化时自动失效
- **过期时间**：默认 7 天

**API 参数**：
- `refresh_summary_cache: bool = False`：是否强制刷新缓存
  - `False`（默认）：优先使用缓存
  - `True`：强制重新生成所有文档总结

**缓存流程**：
```
请求到达 → 批量查询缓存 → 命中的直接使用 → 未命中的并行生成 → 新结果存入缓存 → 合并所有总结
```

### 6.5 RecallTool 缓存机制

系统使用 `RecallToolCache` 缓存单文档召回工具实例：

- 当需要针对特定文档召回时，从缓存获取或创建该文档的专用 RecallTool
- 缓存大小由 `RECALL_TOOL_CACHE_SIZE` 配置（默认 100）
- 避免重复创建工具实例，提升性能

### 6.6 Fallback 机制

系统在多个环节实现了 Fallback 机制：

| 环节 | Fallback 策略 |
|------|--------------|
| 意图识别 | 如果 LLM 返回无效意图，重试最多 3 次，最终默认使用 `SIMPLE_INTERACTION` |
| 子问题生成 | 如果子问题生成失败或返回空列表，使用用户原始问题作为单个召回步骤 |
| 执行循环 | 如果执行步骤超过最大迭代次数（`total_steps × 2`），强制退出循环 |

### 6.7 错误处理

每个处理节点都有独立的错误捕获机制：

- 使用 `try-except` 包装节点逻辑
- 错误时 yield `{"type": "node_error", "node": "xxx", "error": "..."}`
- 确保单个节点的失败不会导致整个流程崩溃
- 向用户返回有意义的错误信息

### 6.8 思考过程展示

API 接口支持 `show_thinking` 参数（默认为 `true`），用于控制是否向客户端展示 AI 的推理过程：

**启用时（show_thinking=true）**：
- 流式响应中包含 `<think>...</think>` 标签
- 客户端可以实时看到 AI 在每个节点的思考内容

**禁用时（show_thinking=false）**：
- 流式响应中不包含思考过程
- 只返回最终的答案内容


---

## 七、工具系统

### 7.1 RecallTool（文档召回工具）

**功能**：通过 HTTP API 从文档知识库中检索相关信息

**核心参数**：
| 参数 | 说明 |
|------|------|
| `api_url` | 召回 API 地址 |
| `index_names` | ES 索引名称列表 |
| `doc_ids` | 限定的文档 ID 列表（可选） |
| `top_n` | 返回结果数量（默认 10） |
| `similarity_threshold` | 相似度阈值（默认 0.2） |
| `vector_similarity_weight` | 向量相似度权重（默认 0.3） |
| `use_rerank` | 是否启用重排序 |

**使用场景**：
- 查找内部文档
- 检索历史记录
- 获取规范、标准文档
- 查询产品信息、技术文档

### 7.2 WebSearchTool（网页搜索工具）

**功能**：从互联网搜索最新信息

**支持的搜索引擎**：
- **Tavily**：提供 AI 优化的搜索结果，包含概要回答
- **Bocha**：博查搜索引擎，支持中文搜索

**核心参数**：
| 参数 | 说明 |
|------|------|
| `api_key` | 搜索引擎 API 密钥 |
| `search_engine` | 搜索引擎类型（"tavily" 或 "bocha"） |
| `max_results` | 最大返回结果数（默认 5） |

**使用场景**：
- 获取最新资讯
- 查找公开数据
- 了解行业动态
- 获取实时信息

---

## 八、会话管理

### 8.1 会话生命周期

```
创建会话 → 添加消息 → 检查压缩 → 触发压缩（如需要） → 关闭会话
```

### 8.2 消息类型

| 类型 | 说明 |
|------|------|
| `USER` | 用户消息 |
| `ASSISTANT` | 助手消息 |
| `COMPRESSION` | 压缩摘要（特殊消息类型） |

### 8.3 会话统计

系统自动维护以下会话统计信息：
- `total_token_count`：会话总 token 数
- `message_count`：消息数量
- `created_at`：创建时间
- `updated_at`：最后更新时间

---

## 九、提示词模板

系统使用多种提示词模板来指导 LLM 完成不同任务：

| 模板 | 用途 |
|------|------|
| `INTENT_RECOGNITION_PROMPT` | 意图识别 |
| `SUB_QUESTION_GENERATION_PROMPT` | 子问题生成 |
| `SIMPLE_INTERACTION_PROMPT` | 简单交互回复 |
| `SINGLE_DOC_SUMMARY_PROMPT` | 单文档总结 |
| `MULTI_DOC_SUMMARY_PROMPT` | 多文档总结 |
| `MULTI_DOC_SUMMARY_SYNTHESIS_PROMPT` | 多文档综合分析 |
| `MULTI_DOC_SUMMARY_FINAL_MERGE_PROMPT` | 多组报告合并 |
| `REVIEW_GENERATION_PROMPT` | 综述生成 |
| `REVIEW_GENERATION_SYNTHESIS_PROMPT` | 综述综合分析 |
| `REVIEW_GENERATION_FINAL_MERGE_PROMPT` | 综述报告合并 |
| `PAPER_REVIEW_PROMPT` | 论文评审 |
| `LITERATURE_QA_PROMPT` | 文献问答 |
| `DOCUMENT_CONDENSED_SUMMARY_PROMPT` | 文档压缩总结 |

---

## 十、流式事件类型

系统在流式输出过程中会产生以下类型的事件：

| 事件类型 | 说明 |
|---------|------|
| `thinking_start` | 思考过程开始 |
| `thinking_end` | 思考过程结束 |
| `thought_chunk` | 思考过程内容片段 |
| `answer_chunk` | 答案内容片段 |
| `final_answer` | 最终答案 |
| `node_complete` | 节点处理完成 |
| `node_error` | 节点处理错误 |
| `doc_summary_init` | 文档总结初始化 |
| `doc_summary_start` | 单个文档总结开始 |
| `doc_summary_chunk` | 文档总结内容片段 |
| `doc_summary_complete` | 单个文档总结完成 |
| `doc_summary_error` | 文档总结错误 |
| `error` | 通用错误 |

---

## 十一、配置参数

### 11.1 系统常量

| 常量 | 默认值 | 说明 |
|------|--------|------|
| `ESTIMATED_SYSTEM_TOKENS` | 2000 | 系统提示预估 token 数 |
| `RESERVED_ANSWER_TOKENS` | 8000 | 答案预留 token 数 |
| `RECALL_TOOL_CACHE_SIZE` | 100 | RecallTool 缓存大小 |
| `MAX_INTENT_RECOGNITION_RETRIES` | 3 | 意图识别最大重试次数 |
| `MAX_CONCURRENT_LLM_CALLS` | 10 | 最大并发 LLM 调用数 |

### 11.2 动态配置参数

以下参数通过请求动态传入：

| 参数 | 说明 |
|------|------|
| `openai_api_key` | OpenAI API 密钥 |
| `openai_api_base` | OpenAI API 基础 URL |
| `model_name` | 模型名称 |
| `max_context_tokens` | 最大上下文 token 数 |
| `search_engine` | 搜索引擎类型 |
| `search_engine_api_key` | 搜索引擎 API 密钥 |
| `recall_*` | 召回相关配置 |

---

## 十二、总结

本智能体系统通过多阶段流水线架构，实现了对学术文献的智能问答处理。系统的核心优势包括：

1. **智能路由**：根据用户意图和文档情况自动选择最优处理策略
2. **高效并行**：多文档场景下的并行处理显著提升响应速度
3. **上下文管理**：完善的会话管理和压缩机制，支持长对话
4. **缓存优化**：文档总结缓存避免重复计算，提升效率
5. **流式输出**：实时流式响应，提升用户体验
6. **容错机制**：多层 Fallback 机制确保系统稳定性

系统设计遵循模块化原则，各节点职责清晰，便于维护和扩展。
