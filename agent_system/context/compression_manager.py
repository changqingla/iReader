"""
å‹ç¼©ç®¡ç†å™¨

å®ç°ä¸Šä¸‹æ–‡å‹ç¼©ç®—æ³•ï¼ŒåŒ…æ‹¬åˆ†å‰²ç‚¹æŸ¥æ‰¾ã€LLMæ‘˜è¦ç”Ÿæˆç­‰
"""

from typing import List, Tuple, Optional
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

from context.models import Message, CompressionRecord, MessageType
from context.session_storage import SessionStorage
from context.token_counter import calculate_tokens
from context.prompts.compression_prompt import (
    build_compression_prompt,
    validate_compression_output,
    extract_summary_content
)
from config import get_settings
from src.utils.logger import get_logger

logger = get_logger(__name__)


class CompressionManager:
    """å‹ç¼©ç®¡ç†å™¨ - å®ç°ä¸Šä¸‹æ–‡å‹ç¼©ç®—æ³•"""
    
    def __init__(
        self,
        llm: ChatOpenAI,
        storage: Optional[SessionStorage] = None
    ):
        """
        åˆå§‹åŒ–å‹ç¼©ç®¡ç†å™¨
        
        Args:
            llm: LLMå®ä¾‹ï¼Œç”¨äºç”Ÿæˆæ‘˜è¦ï¼ˆå¿…éœ€ï¼‰
            storage: ä¼šè¯å­˜å‚¨å®ä¾‹ï¼Œå¦‚æœä¸ºNoneåˆ™åˆ›å»ºæ–°å®ä¾‹
        """
        # LLMå®ä¾‹ï¼ˆä»å¤–éƒ¨ä¼ å…¥ï¼Œä¸å½“å‰è¯·æ±‚ä½¿ç”¨çš„LLMä¿æŒä¸€è‡´ï¼‰
        self.llm = llm
        
        # å­˜å‚¨
        self.storage = storage or SessionStorage()
        
        # é…ç½®å‚æ•°
        self.settings = get_settings()
        self.preserve_ratio = self.settings.compression_preserve_ratio
    
    # ========================================================================
    # ä¸»è¦å‹ç¼©æ–¹æ³•
    # ========================================================================
    
    
    def compress_session(self, session_id: str) -> CompressionRecord:
        """
        å‹ç¼©ä¼šè¯å†å²
        
        è¿™æ˜¯ä¸»è¦çš„å‹ç¼©å…¥å£æ–¹æ³•
        
        Args:
            session_id: ä¼šè¯ID
            
        Returns:
            å‹ç¼©è®°å½•
        """
        logger.info(f"Starting compression for session: {session_id}")
        
        # è·å–æ‰€æœ‰æ´»è·ƒæ¶ˆæ¯
        messages = self.storage.get_messages(session_id, include_compressed=False)
        
        if not messages:
            raise ValueError(f"No messages found for session: {session_id}")
        
        # æ‰§è¡Œå‹ç¼©
        compressed_messages, summary_message, compression_record = self.compress_history(messages)
        
        # ä¿å­˜ç»“æœ
        self._save_compression_result(
            session_id=session_id,
            compressed_messages=compressed_messages,
            summary_message=summary_message,
            compression_record=compression_record
        )
        
        logger.info(
            f"Compression completed: session={session_id}, "
            f"compressed={len(compressed_messages)} messages, "
            f"saved={compression_record.saved_tokens} tokens"
        )
        
        return compression_record
    
    def compress_history(
        self,
        messages: List[Message]
    ) -> Tuple[List[Message], Message, CompressionRecord]:
        """
        æ‰§è¡Œå‹ç¼©ç®—æ³•
        
        æ ¸å¿ƒé€»è¾‘ï¼š
        1. è®¡ç®—æ¯æ¡æ¶ˆæ¯çš„tokenæ•°
        2. ä»åå¾€å‰æ£€æŸ¥ï¼Œæ‰¾åˆ°å³å°†ä½¿ç´¯ç§¯è¾¾åˆ°30%çš„æ¶ˆæ¯
        3. è¯¥æ¶ˆæ¯å°±æ˜¯åˆ†å‰²ç‚¹ä½ç½®ï¼Œéœ€è¦ç¡®ä¿åœ¨å¯¹è¯è¾¹ç•Œï¼ˆassistantå›ç­”ä¹‹åï¼‰
        4. åˆ†ç¦»æ¶ˆæ¯
        5. è°ƒç”¨LLMç”ŸæˆXMLæ‘˜è¦
        6. åˆ›å»ºå‹ç¼©è®°å½•
        
        Args:
            messages: éœ€è¦å‹ç¼©çš„æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            (è¢«å‹ç¼©çš„æ¶ˆæ¯åˆ—è¡¨, æ‘˜è¦æ¶ˆæ¯, å‹ç¼©è®°å½•)
        """
        # è¿‡æ»¤å‡ºæ´»è·ƒæ¶ˆæ¯ï¼ˆæ’é™¤å·²å‹ç¼©çš„ï¼Œä½†ä¿ç•™å‹ç¼©æ‘˜è¦ï¼‰
        active_messages = [
            msg for msg in messages
            if not msg.is_compressed or msg.message_type == MessageType.COMPRESSION
        ]
        
        if not active_messages:
            raise ValueError("No active messages to compress")
        
        # ========================================================================
        # æ­¥éª¤1: è®¡ç®—æ€»tokenæ•°
        # ========================================================================
        total_tokens = sum(msg.token_count for msg in active_messages)
        logger.debug(f"Total tokens before compression: {total_tokens}")
        
        # ========================================================================
        # æ­¥éª¤2: ä»åå¾€å‰æ£€æŸ¥ï¼Œæ‰¾åˆ°å³å°†è¾¾åˆ°30%çš„ä½ç½®
        # ========================================================================
        target_preserve_tokens = int(total_tokens * self.preserve_ratio)
        accumulated_tokens = 0
        split_index = None
        
        for i in range(len(active_messages) - 1, -1, -1):
            current_token = active_messages[i].token_count
            
            # æ£€æŸ¥ï¼šåŠ ä¸Šå½“å‰æ¶ˆæ¯åæ˜¯å¦ä¼šè¾¾åˆ°æˆ–è¶…è¿‡30%
            if accumulated_tokens + current_token >= target_preserve_tokens:
                # å½“å‰æ¶ˆæ¯å°±æ˜¯åˆ†å‰²ç‚¹ä½ç½®ï¼Œéœ€è¦ç¡®ä¿åœ¨å¯¹è¯è¾¹ç•Œ
                if active_messages[i].role == "assistant":
                    # å½“å‰æ¶ˆæ¯æ˜¯assistantï¼Œåˆ†å‰²ç‚¹åœ¨å…¶ä¹‹å
                    split_index = i + 1
                    logger.debug(f"Split point found at assistant message: index={i}")
                    break
                else:
                    # å½“å‰æ¶ˆæ¯æ˜¯userï¼Œå‘å‰æ‰¾æœ€è¿‘çš„assistant
                    for j in range(i - 1, -1, -1):
                        if active_messages[j].role == "assistant":
                            split_index = j + 1
                            logger.debug(f"Split point found at previous assistant: index={j}")
                            break
                    break
            
            # æœªè¾¾åˆ°é˜ˆå€¼ï¼Œç»§ç»­ç´¯ç§¯
            accumulated_tokens += current_token
        
        # ========================================================================
        # æ­¥éª¤3: éªŒè¯åˆ†å‰²ç‚¹
        # ========================================================================
        if split_index is None:
            raise ValueError("Could not find valid split point (no assistant message found)")
        
        # ğŸ”§ è¾¹ç•Œæ¡ä»¶å¤„ç†ï¼šå¦‚æœæœ€åä¸€æ¡æ¶ˆæ¯æœ¬èº«å°±è¶…è¿‡30%
        # split_index >= len(active_messages) è¯´æ˜ä»æœ€åä¸€æ¡æ¶ˆæ¯å¼€å§‹ç´¯ç§¯å°±å·²ç»è¾¾åˆ°30%
        # æ­¤æ—¶åº”è¯¥ä¿ç•™æœ€åä¸€æ¡æ¶ˆæ¯ï¼Œå‹ç¼©å‰é¢æ‰€æœ‰
        if split_index >= len(active_messages):
            last_msg_tokens = active_messages[-1].token_count
            split_index = len(active_messages) - 1  # è‡³å°‘ä¿ç•™æœ€å1æ¡
            logger.warning(
                f"Last message alone ({last_msg_tokens} tokens) exceeds preserve ratio target "
                f"({target_preserve_tokens} tokens). Will preserve it and compress all others. "
                f"Adjusted split_index to {split_index}"
            )
        
        # æœ€ç»ˆéªŒè¯ï¼šå¿…é¡»æœ‰æ¶ˆæ¯å¯å‹ç¼©
        if split_index == 0:
            raise ValueError("Cannot compress: only one message in session")
        
        # ========================================================================
        # æ­¥éª¤4: åˆ†ç¦»æ¶ˆæ¯
        # ========================================================================
        messages_to_compress = active_messages[:split_index]
        messages_to_preserve = active_messages[split_index:]
        
        if not messages_to_compress:
            raise ValueError("No messages to compress")
        
        logger.info(
            f"Messages split: compress={len(messages_to_compress)}, "
            f"preserve={len(messages_to_preserve)}"
        )
        
        # ========================================================================
        # æ­¥éª¤5: è°ƒç”¨LLMç”ŸæˆXMLæ‘˜è¦
        # ========================================================================
        summary_content = self._generate_summary(messages_to_compress)
        # ä½¿ç”¨ä¼ å…¥çš„ LLM çš„æ¨¡å‹åç§°è¿›è¡Œ token è®¡ç®—
        model_name = getattr(self.llm, 'model_name', getattr(self.llm, 'model', 'gpt-3.5-turbo'))
        summary_tokens = calculate_tokens(summary_content, model_name)
        
        logger.info(f"Summary generated: {summary_tokens} tokens")
        
        # ========================================================================
        # æ­¥éª¤6: åˆ›å»ºå‹ç¼©è®°å½•å’Œæ‘˜è¦æ¶ˆæ¯
        # ========================================================================
        compressed_tokens = sum(msg.token_count for msg in messages_to_compress)
        compressed_message_ids = [msg.message_id for msg in messages_to_compress]
        
        # è®¡ç®—å½“å‰æ˜¯ç¬¬å‡ è½®å‹ç¼©
        session_id = messages_to_compress[0].session_id
        compression_history = self.storage.get_compression_history(session_id)
        current_round = len(compression_history) + 1
        
        # åˆ›å»ºå‹ç¼©è®°å½•
        compression_record = CompressionRecord.create_new(
            session_id=session_id,
            round=current_round,
            original_message_count=len(messages_to_compress),
            compressed_token_count=compressed_tokens,
            summary_token_count=summary_tokens,
            summary_content=summary_content,
            compressed_message_ids=compressed_message_ids
        )
        
        # åˆ›å»ºæ‘˜è¦æ¶ˆæ¯
        # ä½¿ç”¨è¢«å‹ç¼©åŒºé—´çš„ç¬¬ä¸€æ¡æ¶ˆæ¯çš„sequence_number
        # è¿™æ ·æ‘˜è¦ä¼šåœ¨æ­£ç¡®çš„ä½ç½®ï¼ˆè¢«å‹ç¼©æ¶ˆæ¯çš„å¼€å§‹ä½ç½®ï¼‰
        # æ—§çš„æ‘˜è¦ï¼ˆå¦‚æœæœ‰ï¼‰ä¼šè¢«æ ‡è®°ä¸ºis_compressed=TRUEï¼Œä¸ä¼šå†²çª
        summary_seq = messages_to_compress[0].sequence_number
        summary_message = Message.create_compression_message(
            session_id=session_id,
            content=summary_content,
            token_count=summary_tokens,
            compression_id=compression_record.compression_id,
            sequence_number=summary_seq
        )
        
        logger.debug(
            f"Summary message created with sequence_number={summary_seq} "
            f"(replacing compressed messages seq={messages_to_compress[0].sequence_number}-{messages_to_compress[-1].sequence_number})"
        )
        
        logger.info(
            f"Compression record created: round={current_round}, "
            f"ratio={compression_record.compression_ratio:.2%}"
        )
        
        return messages_to_compress, summary_message, compression_record
    
    # ========================================================================
    # ç§æœ‰è¾…åŠ©æ–¹æ³•
    # ========================================================================
    
    def _generate_summary(self, messages: List[Message]) -> str:
        """
        è°ƒç”¨LLMç”Ÿæˆæ‘˜è¦
        
        Args:
            messages: éœ€è¦æ€»ç»“çš„æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            XMLæ ¼å¼çš„æ‘˜è¦å†…å®¹
            
        Raises:
            Exception: LLMè°ƒç”¨å¤±è´¥æˆ–è¾“å‡ºæ ¼å¼ä¸æ­£ç¡®
        """
        logger.debug(f"Generating summary for {len(messages)} messages")
        
        # æ„å»ºPrompt
        prompt = build_compression_prompt(messages)
        
        # è°ƒç”¨LLM
        response = self.llm.invoke([HumanMessage(content=prompt)])
        output = response.content
        
        # æå–XMLå†…å®¹
        summary = extract_summary_content(output)
        
        # éªŒè¯è¾“å‡ºæ ¼å¼
        if not validate_compression_output(summary):
            error_msg = f"LLM output does not match expected XML format: {summary[:100]}..."
            logger.error(error_msg)
            raise ValueError(error_msg)
        
        logger.info("Summary generated successfully")
        return summary
    
    def _save_compression_result(
        self,
        session_id: str,
        compressed_messages: List[Message],
        summary_message: Message,
        compression_record: CompressionRecord
    ) -> None:
        """
        ä¿å­˜å‹ç¼©ç»“æœ
        
        Args:
            session_id: ä¼šè¯ID
            compressed_messages: è¢«å‹ç¼©çš„æ¶ˆæ¯
            summary_message: æ‘˜è¦æ¶ˆæ¯
            compression_record: å‹ç¼©è®°å½•
        """
        # 1. æ ‡è®°è¢«å‹ç¼©çš„æ¶ˆæ¯
        compressed_message_ids = [msg.message_id for msg in compressed_messages]
        self.storage.mark_messages_compressed(
            message_ids=compressed_message_ids,
            compression_id=compression_record.compression_id
        )
        
        # 2. æ·»åŠ æ‘˜è¦æ¶ˆæ¯
        self.storage.add_message(summary_message)
        
        # 3. ä¿å­˜å‹ç¼©è®°å½•
        self.storage.save_compression_record(compression_record)
        
        # 4. æ›´æ–°ä¼šè¯çš„å‹ç¼©è®¡æ•°
        self.storage.increment_compression_count(session_id)
        
        # 5. æ›´æ–°ä¼šè¯tokenç»Ÿè®¡ï¼ˆå‡å»è¢«å‹ç¼©çš„ï¼ŒåŠ ä¸Šæ‘˜è¦ï¼‰
        session = self.storage.get_session(session_id)
        if session:
            new_total = (
                session.total_token_count 
                - compression_record.compressed_token_count 
                + compression_record.summary_token_count
            )
            self.storage.update_session_stats(
                session_id=session_id,
                total_tokens=new_total,
                message_count=session.message_count
            )
        
        logger.info(f"Compression result saved for session: {session_id}")

